:sectnums:
:sectnumlevels: 1
:toc: macro
:toclevels: 2

image::doc/images/UnionLogo.png["UnionLogo", width=800px]

toc::[]

== Overview
In traditional Multi-Agent Exploration (MAE) methods, all agents start in the same place and start with a shared coordinate system; and once the relative transformation missed due to localization failures, the MAE system will be very fregial and easily crash.
This framework provide a novel Autonomous Exploration paradigm, all the agents can start in the darkness, without knowing anything about *where they are*, *where each other are*, and *what the environment looks like*. As the MAE system explorer individually, *MetaUnion* helps to find associated overlaps among different agents and solve the above three challenges gradually; and most importantly, *MetaUnion* can incrementally update the feature learning ability for new observed areas. In a summary, our key contributions includes:

* *Multi-Agent Localiztion without Initial Transformation;*
* *Multi-Agent Hierarchical Exploration;*
* *Incremental Lifelong Localization.*

=== System Structure

image::doc/images/MetaUnion.png["MetaUnion", width=850px]

MetaUnion mainly contains three key modules within the framework: *AutoMerge*, *MrExplorer*, and *BioSLAM*. In the begining, each agent is randomly assigned at a new envionrment, and has neither information about other agents' localization, nor place recognition ability for the new areas, and conduct single-agent exploration individually.
When the trajectries of different agents have overlaps, *AutoMerge* module can automatically detect the data association between agents, and estimate the relative positions for them. Based on the relative transformation, *MrExplorer* can divide the agent into different groups based on their connections, and apply hierarichal exploration for individual agent. Parallel with the above procedure, *BioSLAM* constructs a dual-memory system to memorize the large-scale and long-duration place features. As the MAS system explorer to bigger area, their cooperation ability and place recognition ability are improved gradually.

== Software

To quickly install all the necessary softwares for MetaUnion, please following the instructions,

[source,bash]
----

git clone --recurse-submodules -j8 https://github.com/MetaSLAM/MetaUnion.git
sh 
sh tmux_run.sh
----

=== AutoMerge

[source,txt]
----
AutoMerge                  # Dataset root path
├─ data/                   # Directory to store datasets, training model and results
│  ├─download.sh           # Script for data and model downloading
│  config/                 
│  ├─dataset               # Configure for datasets
│  ├─network               # Configure for networks
├─ tests                   # Testing code
│  ├─test.py               # python demo code
│  └─demo.ipynb            # jupyter demo code
├─ src/                    
│  └─automerge/            # Main source files
│     ├─dataloader         # Dataloader 
│     ├─detection          # Place Recognition for Loop Closure Detection
│     ├─merge              # Backend Map Merging
│     ├─model              # Place Descriptors
│     ├─utils              # Utils, include data processing, evalaution metric, etc.
│     └─__init__.py        # init file
├─ doc/                    # Documentation
├─ pyproject.toml          
├─ requirements.txt
└─ setup.py
----

=== MrExplorer

[source,txt]
----
AutoMerge                  # Dataset root path
├─ data/                   # Directory to store datasets, training model and results
│  ├─download.sh           # Script for data and model downloading
│  config/                 
│  ├─dataset               # Configure for datasets
│  ├─network               # Configure for networks
├─ tests                   # Testing code
│  ├─test.py               # python demo code
│  └─demo.ipynb            # jupyter demo code
├─ src/                    
│  └─automerge/            # Main source files
│     ├─dataloader         # Dataloader 
│     ├─detection          # Place Recognition for Loop Closure Detection
│     ├─merge              # Backend Map Merging
│     ├─model              # Place Descriptors
│     ├─utils              # Utils, include data processing, evalaution metric, etc.
│     └─__init__.py        # init file
├─ doc/                    # Documentation
├─ pyproject.toml          
├─ requirements.txt
└─ setup.py
----

=== BioSLAM

[source,txt]
----
AutoMerge                  # Dataset root path
├─ data/                   # Directory to store datasets, training model and results
│  ├─download.sh           # Script for data and model downloading
│  config/                 
│  ├─dataset               # Configure for datasets
│  ├─network               # Configure for networks
├─ tests                   # Testing code
│  ├─test.py               # python demo code
│  └─demo.ipynb            # jupyter demo code
├─ src/                    
│  └─automerge/            # Main source files
│     ├─dataloader         # Dataloader 
│     ├─detection          # Place Recognition for Loop Closure Detection
│     ├─merge              # Backend Map Merging
│     ├─model              # Place Descriptors
│     ├─utils              # Utils, include data processing, evalaution metric, etc.
│     └─__init__.py        # init file
├─ doc/                    # Documentation
├─ pyproject.toml          
├─ requirements.txt
└─ setup.py
----

== Multi-Agent Localization

[source,yaml]
----
DATA:
    OFFLINE_LENGTH: 100 # Set for desire testing length
----
Use `OFFLINE_LENGTH` to set the length for each agent.

[source,bash]
----
python src/offline_merging.py
----

In the current `global_rough_align` step, we will use spectral clustering method to divide agents into different groups based on their connections.

== Multi-Agent Exploration

=== Start Docker

[source,bash]
----
cd AUTOMERGE
sh doc/bin/start_docker.sh
sh tmux_run.sh
----

This will enable the `metaslam/automerge` docker image, within which we already enabled the LiDAR odometry and AutoMerge Server. 
The `tmux_run.sh` will automatically trigger `online_detector.py` and `online_merging.py`.
Note, we also need to trigger `online_visualizer.py` for online visualization (in progress).

=== Visualization

Outside the docker, subscibe `/global_map` with `world` frame with `rviz`. Different un-merged maps will be visualized along the z-axis (`index*30`).

== Lifelong Localization

See the demo tutorial in the link:tests/demo.ipynb[jupyter] and link:tests/test.py[python] version.

=== Configure Datasets

Download Pittsburgh datasets for online map merging.
https://drive.google.com/drive/folders/19AK8jc6yZpKN6Ub_ILGJaceZixpbwKcV?usp=sharing

Download pre-trained models and set path
[source,bash]
----
cd data && sh download.sh
echo "export ROS_IP='172.17.0.1' " >> ~/.bashrc
echo "export MASTER_IP='172.17.0.2' " >> ~/.bashrc
echo "export ROS_MASTER_URI=http://$MASTER_IP:11311/ " >> ~/.bashrc
echo "export BAG_PATH='$PATH_TO_PITT_ROS_BAGS' " >> ~/.bashrc
source ~/.bashrc
----
And the following difference matrix in the `data/results/`. Then set `ROS_IP` to enable communication between docker and host computer.
Finally, export dataset path, and replace `PATH_TO_PITT_ROS_BAGS` to the Pittusbrugh rosbags.


== TODO List

* Use Waymo datasets
* Setup Lgsvl Simulation
